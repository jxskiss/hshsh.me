<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algorithm on hshsh&#39;s little site</title>
    <link>http://hshsh.me/tags/algorithm/</link>
    <description>Recent content in Algorithm on hshsh&#39;s little site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 21 Oct 2017 23:00:00 +0800</lastBuildDate>
    
	<atom:link href="http://hshsh.me/tags/algorithm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>一致性哈希算法学习笔记</title>
      <link>http://hshsh.me/post/2017-10-21-consistent-hashing/</link>
      <pubDate>Sat, 21 Oct 2017 23:00:00 +0800</pubDate>
      
      <guid>http://hshsh.me/post/2017-10-21-consistent-hashing/</guid>
      <description>一致性哈希算法（Consistent Hashing）学习笔记。
主要内容从参考资料中摘抄，版权归原作者所有。
参考资料：
 一致性哈希算法及其在分布式系统中的应用 深入云存储系统Swift核心组件：Ring实现原理剖析      &amp;#20998;&amp;#24067;&amp;#24335;&amp;#32531;&amp;#23384;&amp;#38382;&amp;#39064;&amp;#182;假设我们有一个网站，最近发现随着流量增加，服务器压力越来越大，之前直接读写数据库的方式不太给力了，于是我们想引入 Memcached 作为缓存机制。现在我们一共有三台机器可以作为 Memcached 服务器，如下图所示。
很显然，最简单的策略是将每一次 Memcached 请求随机发送到一台 Memcached 服务器，但是这种策略可能会带来两个问题：
 同一份数据可能被存在不同的机器上而造成数据冗余； 有可能某数据已经被缓存但是访问却没有命中，因为无法保证对相同 key 的访问都被发送到相同的服务器。  因此，随机策略无论是时间效率还是空间效率都非常不好。
要解决上述问题需要做到如下一点：保证对相同 key 的访问会被发送到相同的服务器。很多方法可以实现这一点，最常用的方法是计算哈希。例如对于每次访问，可以按如下算法计算哈希值：
h = Hash(key) % 3  其中，Hash 是一个从字符串到正整数的哈希映射函数。这样，如果我们将 Memcached Server 分别编号为 0、1、2，那么就可以根据上述算式和 key 计算出服务器编号 h，然后去访问。
这个方法虽然解决了上面提到的两个问题，但是存在一些其他的问题，如果将上述方法抽象：
h = Hash(key) % N  这个算式计算每个 key 的请求应该被发送到哪台服务器，其中 N 为服务器的数量，并且服务器按照 0..(N-1) 进行编号。
这个算法的问题在于容错性和扩展性不好。所谓容错性是指当系统中某一个或几个服务器变得不可用时，整个系统是否可以正确高效运行；而扩展性是指当加入新的服务器后，整个系统是否可以正确高效运行。
现在假设有一台服务器宕机了，那么为了填补空缺，要将宕机的服务器从编号列表中移除，后面的服务器按顺序前移一位并将其编号值减一，此时每个 key 就要按 h = Hash(key) % (N-1) 重新计算；同样，如果新增了一台服务器，虽然原有服务器编号不用改变，但是要按 h = Hash(key) % (N+1) 重新计算哈希值。因此系统中一旦有服务器变更，大量的 key 会被重定位到不同有服务器从而造成大量的缓存不命中。而这种情况在分布式系统中是非常糟糕的。</description>
    </item>
    
  </channel>
</rss>